import os
import json
import re
import html
import hashlib
import threading
from urllib.parse import urlparse
from pathlib import Path
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests

from ..base_system.context import GlobalContext
from ..base_system.storage_system import FileCleaner
from .epub_generator import EpubGenerator

# é»˜è®¤ç« èŠ‚æ¨¡æ¿å†…å®¹ï¼ˆå½“å¯ç”¨æ¨¡æ¿åŠŸèƒ½ä½†æŒ‡å®šæ–‡ä»¶ä¸å­˜åœ¨æ—¶è‡ªåŠ¨ç”Ÿæˆï¼‰
DEFAULT_CHAPTER_TEMPLATE = (
    "{title}\n\n"  # æ ‡é¢˜å ä½ç¬¦
    "{{for p in paragraphs}}    {p}\n"  # æ¯æ®µå‰ 4 ç©ºæ ¼ï¼Œåç»­é€»è¾‘ä¼šæ›¿æ¢ä¸ºå…¨è§’æˆ– &nbsp;
    "{{end}}"
)

class BookManager(object):
    """ä¹¦ç±å­˜å‚¨æ§åˆ¶å™¨"""
    def __init__(self, save_path: str, book_id: str, book_name: str, author: str, tags: list, description: str):
        # ä¹¦æœ¬ä¿¡æ¯ç¼“å­˜
        self.save_dir = Path(save_path)
        self.book_id = book_id
        self.book_name = book_name
        self.author = author
        self.end = True if (tags and tags[0] == "å·²å®Œç»“") else False
        self.tags = "|".join(tags)
        self.description = description

        # åˆå§‹åŒ–
        self.config = GlobalContext.get_config()
        self.logger = GlobalContext.get_logger()

        # ç¼“å­˜
        self.downloaded: Dict[str, List[str]] = {}

        # çŠ¶æ€æ–‡ä»¶è·¯å¾„
        filename = f"chapter_status_{book_id}.json"
        self.status_folder = self.config.get_status_folder_path
        self.status_file = self.status_folder / filename

        self._load_download_status()
        # æ ‡è®°ï¼šæ®µè¯„åª’ä½“æ˜¯å¦å·²åœ¨ä¸‹è½½é˜¶æ®µé¢„å–ï¼Œé¿å… finalize å†æ¬¡å¤„ç†
        self._media_prefetched = False
    # å·²ç§»é™¤æ®µè¯„å›¾ç‰‡è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆé™é»˜ä¸‹è½½ï¼‰
        # æ®µè¯„åª’ä½“é¢„å–æ‰§è¡Œå™¨ï¼ˆåœ¨ä¿å­˜æ®µè¯„æ—¶å¹¶å‘å¯åŠ¨ï¼‰
        try:
            from concurrent.futures import ThreadPoolExecutor as _TP
            self._media_prefetch_executor = _TP(max_workers=2)
        except Exception:
            self._media_prefetch_executor = None

    def _load_download_status(self):
        """åŠ è½½å®Œæ•´çš„ä¸‹è½½çŠ¶æ€"""
        try:
            if self.status_file.exists():
                with self.status_file.open("r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.book_name = data.get("book_name", "")
                    self.author = data.get("author", "")
                    self.tags = data.get("tags", "")
                    self.description = data.get("description", "")
                    self.downloaded = data.get("downloaded", {})
        except Exception as e:
            self.logger.error(f"çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            self.downloaded = {}

    def save_chapter(self, chapter_id: str, title: str, content: str):
        """ä¿å­˜ç« èŠ‚å†…å®¹ï¼Œæ”¯æŒæ•£è£…ä¿å­˜ï¼ˆEPUB ä¸‹ç”Ÿæˆå®Œæ•´ XHTMLï¼‰"""
        # åœ¨å†™å…¥ç¼“å­˜å‰å¯åº”ç”¨è‡ªå®šä¹‰ç« èŠ‚æ¨¡æ¿
        processed_content = content
        try:
            if getattr(self.config, 'enable_chapter_template', False):
                tpl_path = getattr(self.config, 'chapter_template_file', 'chapter_template.txt')
                tpl_file = Path(tpl_path)
                # æ”¯æŒç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºè¿è¡Œç›®å½• / é…ç½®çŠ¶æ€ç›®å½•ï¼‰
                if not tpl_file.exists():
                    alt = self.status_folder / tpl_path
                    if alt.exists():
                        tpl_file = alt
                if tpl_file.exists():
                    raw_tpl = tpl_file.read_text(encoding='utf-8', errors='ignore')
                    processed_content = self._render_chapter_template(raw_tpl, title, content)
                else:
                    # æ¨¡æ¿ä¸å­˜åœ¨ï¼šå°è¯•è‡ªåŠ¨ç”Ÿæˆé»˜è®¤æ¨¡æ¿
                    try:
                        tpl_file.parent.mkdir(parents=True, exist_ok=True)
                        tpl_file.write_text(DEFAULT_CHAPTER_TEMPLATE, encoding='utf-8')
                        self.logger.info(f"ç« èŠ‚æ¨¡æ¿æœªæ‰¾åˆ°ï¼Œå·²è‡ªåŠ¨ç”Ÿæˆé»˜è®¤æ¨¡æ¿: {tpl_file}")
                        processed_content = self._render_chapter_template(DEFAULT_CHAPTER_TEMPLATE, title, content)
                    except Exception as ge:
                        self.logger.warning(f"ç« èŠ‚æ¨¡æ¿æœªæ‰¾åˆ°ä¸”è‡ªåŠ¨ç”Ÿæˆå¤±è´¥: {tpl_path} ({ge})")
        except Exception as e:
            self.logger.debug(f"ç« èŠ‚æ¨¡æ¿å¤„ç†å¤±è´¥: {e}")

        # ---- æ¨¡æ¿è¾“å‡ºåå¤„ç† ----
        try:
            if getattr(self.config, 'enable_chapter_template', False):
                # 1) EPUBï¼ˆéæ•£è£…ï¼‰åœºæ™¯ä¸‹ EpubGenerator é€šå¸¸ä¼šå†åŒ…ä¸€å±‚ <h1>æ ‡é¢˜ï¼Œé¿å…é¦–è¡Œé‡å¤æ ‡é¢˜
                if (not self.config.bulk_files) and self.config.novel_format == 'epub':
                    lines = [l for l in processed_content.split('\n')]
                    # è·³è¿‡å‰å¯¼ç©ºè¡Œæ‰¾ç¬¬ä¸€è¡Œå®é™…å†…å®¹
                    first_idx = 0
                    while first_idx < len(lines) and lines[first_idx].strip() == '':
                        first_idx += 1
                    if first_idx < len(lines) and lines[first_idx].strip() == title.strip():
                        lines.pop(first_idx)
                        processed_content = '\n'.join(lines).lstrip('\n')
                # 2) å°†ç”¨æˆ·ä»¥å››ä¸ªç©ºæ ¼æœŸæœ›çš„â€œä¸­æ–‡é¦–è¡Œç¼©è¿›â€è½¬æ¢ä¸ºå…¨è§’ç©ºæ ¼ï¼ˆæˆ– &emsp;&emsp;ï¼‰é¿å… HTML æ¸²æŸ“åæ‰ç©ºæ ¼
                # ä¸¤ä¸ªå…¨è§’ç©ºæ ¼â€œã€€ã€€â€åœ¨å¤§å¤šæ•°é˜…è¯»å™¨ä¸­æ›´ç¨³å®šã€‚
                processed_content = re.sub(r'(?m)^( {4})(\S)', r'ã€€ã€€\2', processed_content)
                # 3) è‹¥éœ€è¦ç›´æ¥ä¿ç•™æ¨¡æ¿ä¸­å†™ä¸‹çš„å‰å¯¼ç©ºæ ¼ï¼ˆåŒ…å«å¾ªç¯é‡Œå†™çš„    {p} å½¢å¼ï¼‰ï¼Œè‡ªåŠ¨è½¬ä¸º &nbsp; ä¿è¯ EPUB é˜…è¯»å™¨ä¸ä¼šæŠ˜å 
                if self.config.novel_format == 'epub':
                    # ä»…è½¬æ¢æ¯ä¸€è¡Œè¡Œé¦–è¿ç»­ç©ºæ ¼ï¼Œé¿å…ç ´åè¡Œå†…æ™®é€šç©ºæ ¼ã€‚
                    def _lead_space_to_nbsp(m):
                        return '&nbsp;' * len(m.group(1))
                    processed_content = re.sub(r'(?m)^( +)', _lead_space_to_nbsp, processed_content)
        except Exception:
            pass

        self.downloaded[chapter_id] = [title, processed_content]
        if self.config.bulk_files:
            bulk_dir = self.save_dir / self.book_name
            bulk_dir.mkdir(parents=True, exist_ok=True)

            if self.config.novel_format == "epub":
                suffix = ".xhtml"
                # ä½¿ç”¨ processed_content è€Œä¸æ˜¯åŸå§‹ contentï¼Œä¸”ä¸å†å¼ºåˆ¶åŠ å…¥æ ‡é¢˜ï¼ˆè®©æ¨¡æ¿è‡ªè¡Œæ§åˆ¶ï¼‰
                xhtml_template = f'''<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>{title}</title>
  <meta charset="utf-8" />
  <style>p{{margin:0 0 0.8em 0;}}</style>
</head>
<body>
{processed_content}
</body>
</html>'''
                file_content = xhtml_template
            else:
                suffix = ".txt"
                # TXT æ•£è£…æ–‡ä»¶è‹¥æ¨¡æ¿å·²å«æ ‡é¢˜ï¼Œé¿å…é‡å¤ï¼šæ£€æµ‹é¦–è¡Œï¼ˆå¿½ç•¥ç©ºè¡Œï¼‰æ˜¯å¦å·²æ˜¯æ ‡é¢˜
                _lines = processed_content.split('\n')
                _i = 0
                while _i < len(_lines) and _lines[_i].strip() == '':
                    _i += 1
                if _i < len(_lines) and _lines[_i].strip() == title.strip():
                    file_content = processed_content
                else:
                    file_content = f"{title}\n\n{processed_content}"

            # æŠŠ title ä¸­çš„éæ³•æ–‡ä»¶åå­—ç¬¦æ›¿æ¢æ‰
            safe_title = "".join(c for c in title if c.isalnum() or c in "-_ ")
            filename = f"{safe_title}{suffix}"
            file_path = bulk_dir / filename

            with file_path.open("w", encoding="utf-8") as f:
                f.write(file_content)

            self.logger.debug(f"ç« èŠ‚æ•£è£…ä¿å­˜ï¼š{file_path}")
        else:
            self.save_download_status()

        self.logger.debug(f"ç« èŠ‚ {chapter_id} ç¼“å­˜æˆåŠŸ")

    def _render_chapter_template(self, template: str, title: str, raw_content: str) -> str:
        """æ¸²æŸ“è‡ªå®šä¹‰ç« èŠ‚æ¨¡æ¿ã€‚
        æ”¯æŒå ä½ç¬¦:
          {title} ç« èŠ‚æ ‡é¢˜
          {content} åŸå§‹å†…å®¹ï¼ˆä¸åšé¢å¤–ç¼©è¿›ï¼‰
          {text} æ•´ä½“å†…å®¹å‰å¯ç»Ÿä¸€åŠ ç¼©è¿›ï¼ˆå³ä¿æŒåŸæ¢è¡Œï¼‰
          {paragraphs} æŒ‰æ®µè½å¤„ç†æ‹¼æ¥ï¼ˆæ®µè½åˆ†éš”: ç©ºè¡Œæˆ–æ¢è¡Œï¼‰
        é¢å¤–æ”¯æŒä¸€ä¸ªç®€æ˜“å¾ªç¯ï¼š
          {{for p in paragraphs}}...{p}...{{end}}
        åœ¨å¾ªç¯ä¸­ä½¿ç”¨ {p} å ä½ç¬¦ä»£è¡¨å•ä¸ªæ®µè½æ–‡æœ¬ï¼ˆå¯å«å‰ç¼€ç¼©è¿›ï¼‰
        ç‰¹æ®Šç¼©è¿›è§„åˆ™ï¼š
          æ¨¡æ¿ä¸­å‡ºç° "{text}" å‰è‹¥æœ‰ 4 ä¸ªæˆ–æ›´å¤šç©ºæ ¼ç´§è´´ï¼Œå¯è§†ä¸ºç¼©è¿›æŒ‡ä»¤ï¼Œå¯¹æ•´æ®µåº”ç”¨åŒæ ·å‰ç¼€ã€‚
          æ¨¡æ¿ä¸­å‡ºç° "{paragraph}" ç±»ä¼¼ï¼›ä¸è¿‡å»ºè®®åœ¨å¾ªç¯è¯­æ³•ä¸­ä½¿ç”¨ã€‚
        """
        try:
            # ç»Ÿä¸€è¡Œç»“æŸ
            raw = raw_content.replace('\r\n', '\n').replace('\r', '\n')
            # åˆ‡åˆ†æ®µè½ï¼ˆç®€å•è§„åˆ™ï¼šæŒ‰å•ä¸ªæ¢è¡Œæ‹†ï¼Œä¿ç•™ç©ºè¡Œï¼‰
            paragraphs = [p for p in raw.split('\n')]
            # åŸºç¡€ä¸Šä¸‹æ–‡
            ctx = {
                'title': title,
                'content': raw,
            }
            # å¤„ç†ç¼©è¿›ï¼šè‹¥æ¨¡æ¿ä¸­ç›´æ¥ä½¿ç”¨ {text}ï¼Œä¸æ”¹ï¼›
            # è‹¥ç”¨æˆ·å†™æˆ "    {text}" åˆ™æŠŠå‰å¯¼ç©ºæ ¼ä½œä¸ºæ•´å—ç¼©è¿›
            def apply_block_indent(placeholder: str, block: str) -> str:
                pattern = re.compile(rf'^(?P<indent>[ \t]+)\{{{placeholder}\}}$', re.MULTILINE)
                def repl(m):
                    ind = m.group('indent')
                    new_lines = [ind + ln if ln.strip() else ln for ln in block.split('\n')]
                    return '\n'.join(new_lines)
                return re.sub(pattern, repl, template)

            rendered = template
            # ç®€æ˜“å¾ªç¯å®ç°
            loop_pattern = re.compile(r'\{\{for p in paragraphs\}\}(.*?)\{\{end\}\}', re.DOTALL)
            def loop_repl(m):
                body = m.group(1)
                out_parts = []
                for para in paragraphs:
                    # å¤„ç†å•æ®µç¼©è¿›ï¼š è‹¥ body ä¸­å‡ºç°ç‹¬ç«‹è¡Œ "    {paragraph}" -> åº”ç”¨ç¼©è¿›åˆ°è¯¥æ®µ
                    b = body
                    # {paragraph} ç›´æ¥æ›¿æ¢ä¸º paraï¼ˆä¿æŒåŸæ ·ï¼‰
                    b = b.replace('{paragraph}', para)
                    # {p} å ä½ç¬¦
                    b = b.replace('{p}', para)
                    out_parts.append(b)
                return ''.join(out_parts)
            rendered = re.sub(loop_pattern, loop_repl, rendered)

            # paragraphs æ‹¼æ¥ï¼ˆä¿æŒåŸè¡Œç»“æ„ï¼‰
            rendered = rendered.replace('{paragraphs}', '\n'.join(paragraphs))
            # text è¯­ä¹‰ï¼šæ•´ä½“å†…å®¹ï¼Œè‹¥ä½¿ç”¨ "    {text}" åº”å¥—ç¼©è¿›
            if '{text}' in rendered:
                rendered = rendered.replace('{text}', raw)
            # content ä¿ç•™åŸå§‹
            rendered = rendered.replace('{content}', raw)
            # title
            rendered = rendered.replace('{title}', title)
            return rendered
        except Exception as e:
            self.logger.debug(f"ç« èŠ‚æ¨¡æ¿æ¸²æŸ“å¼‚å¸¸: {e}")
            return raw_content

    def save_segment_comments(self, chapter_id: str, payload: dict):
        """
        ä¿å­˜æŸä¸ªç« èŠ‚çš„æ®µè¯„æ•°æ®åˆ°çŠ¶æ€ç›®å½•ä¸‹çš„ JSON æ–‡ä»¶ã€‚
        æ–‡ä»¶è·¯å¾„: <status_folder>/segment_comments/<chapter_id>.json
        """
        try:
            seg_dir = self.status_folder / "segment_comments"
            seg_dir.mkdir(parents=True, exist_ok=True)
            out_path = seg_dir / f"{chapter_id}.json"
            with out_path.open("w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False, indent=2)
            self.logger.debug(f"æ®µè¯„å·²ä¿å­˜: {out_path}")
            # ç”¨æˆ·å¯è§æç¤ºï¼šå‘ŠçŸ¥æ®µè¯„ä¿å­˜å®Œæˆï¼ˆç”¨äºè¿›åº¦æ¡å¤–çš„å¿ƒè·³æ„ŸçŸ¥ï¼‰
            try:
                paras = payload.get("paras") if isinstance(payload, dict) else None
                seg_cnt = 0
                cmts_total = 0
                if isinstance(paras, dict):
                    for _k, _v in paras.items():
                        try:
                            c = int((_v or {}).get("count", 0))
                        except Exception:
                            c = 0
                        if c > 0:
                            seg_cnt += 1
                            cmts_total += c
                self.logger.info(f"[æ®µè¯„] ç« èŠ‚ {chapter_id} å·²ä¿å­˜ï¼šå« {seg_cnt} æ®µæœ‰è¯„è®ºï¼Œå…± {cmts_total} æ¡ï¼ˆå‰ {getattr(self.config,'segment_comments_top_n',10)} æ¡å·²å†™å…¥å±•ç¤ºï¼‰")
            except Exception:
                pass
            # åŒæ­¥å¯åŠ¨æ®µè¯„åª’ä½“ï¼ˆå›¾ç‰‡+å¤´åƒï¼‰é¢„å–ï¼šä¸ä¿å­˜åŒæ—¶è¿›è¡Œ
            if getattr(self.config, "enable_segment_comments", False):
                try:
                    top_n = int(getattr(self.config, "segment_comments_top_n", 10))
                except Exception:
                    top_n = 10
                # ä»…å½“é…ç½®å…è®¸ä¸‹è½½è¯„è®ºå›¾ç‰‡æˆ–å¤´åƒï¼ˆå¤´åƒå§‹ç»ˆä¼šè¢«å°è¯•ï¼‰æ‰å¯åŠ¨
                allow_images = bool(getattr(self.config, "download_comment_images", True))
                if allow_images or True:  # å¤´åƒå§‹ç»ˆå¤„ç†
                    if self._media_prefetch_executor is not None:
                        try:
                            self._media_prefetch_executor.submit(self._prefetch_media, payload, top_n)
                        except Exception:
                            # å›é€€ç›´æ¥è°ƒç”¨ï¼ˆé˜»å¡å½“å‰çº¿ç¨‹ï¼‰
                            self._prefetch_media(payload, top_n)
                    else:
                        # æ— æ‰§è¡Œå™¨ï¼ˆæç«¯æƒ…å†µï¼‰ç›´æ¥è°ƒç”¨
                        self._prefetch_media(payload, top_n)
        except Exception as e:
            self.logger.debug(f"æ®µè¯„ä¿å­˜å¤±è´¥: {e}")

    def save_error_chapter(self, chapter_id, title):
        """ä¿å­˜ä¸‹è½½é”™è¯¯ç« èŠ‚"""
        self.downloaded[chapter_id] = [title, "Error"]
        self.save_download_status()
        self.logger.debug(f"ç« èŠ‚ {chapter_id} ä¸‹è½½é”™è¯¯è®°å½•ç¼“å­˜æˆåŠŸ")

    def finalize_spawn(self, chapters, result):
        """ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶"""
        if not self.config.bulk_files:
            # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥å›¾ç‰‡é¢„å–ä»»åŠ¡å®Œæˆï¼Œä¿è¯ç”Ÿæˆ EPUB æ—¶å›¾ç‰‡å·²è½åœ°
            try:
                if hasattr(self, "_media_prefetch_executor") and self._media_prefetch_executor:
                    self._media_prefetch_executor.shutdown(wait=True)
            except Exception:
                pass
            output_file = self.save_dir / f"{self.book_name}.{self.config.novel_format}"
            if output_file.exists():
                os.remove(output_file)
            if self.config.novel_format == "epub":
                # ç”ŸæˆEPUBéª¨æ¶
                epub = EpubGenerator(
                    self.book_id,
                    self.book_name,
                    "zh-CN",
                    self.author,
                    self.description,
                    "ç•ªèŒ„å°è¯´",
                )

                epub.add_chapter(
                    "ä¹¦ç±ç®€ä»‹",
                    f"<h1>ä¹¦ç±ç®€ä»‹</h1><p><small>{self.tags}</small></p><p>{re.sub(r'\n+', '</p><p>', self.description)}</p>",
                )

                for chapter in chapters:
                    chapter_id = chapter["id"]
                    title = self.downloaded.get(chapter_id, [chapter["title"], None])[0]
                    content = self.downloaded.get(
                        chapter_id,
                        [None, "<p>Download Faild or Didn't Download Finish!</p>"],
                    )[1]

                    # è‹¥å¯ç”¨æ®µè¯„åŠŸèƒ½ï¼Œå°è¯•ä¸ºè¯¥ç« èŠ‚ç”Ÿæˆæ®µè¯„é¡µé¢ï¼Œå¹¶åœ¨ç« èŠ‚æœ«å°¾åŠ å…¥é“¾æ¥
                    seg_link = ""
                    # ä¸ºç« èŠ‚å»ºç«‹ç¨³å®šæ–‡ä»¶åï¼Œä¾¿äºæ®µè¯„é¡µé¢å›é“¾
                    chapter_file = f"chapter_{chapter_id}.xhtml"
                    if getattr(self.config, "enable_segment_comments", False):
                        seg_data = self._load_segment_comments_json(chapter_id)
                        if seg_data is not None:
                            # è‹¥æœªåœ¨ä¸‹è½½é˜¶æ®µé¢„å–åª’ä½“ï¼Œåˆ™æ­¤å¤„å…œåº•é¢„å–ä¸€æ¬¡
                            if not self._media_prefetched:
                                try:
                                    try:
                                        top_n = int(getattr(self.config, "segment_comments_top_n", 10))
                                    except Exception:
                                        top_n = 10
                                    self._prefetch_media(seg_data, top_n)
                                except Exception:
                                    pass
                            comments_file = f"comments_{chapter_id}.xhtml"
                            comments_title = f"{title} - æ®µè¯„"
                            # åœ¨ä¿®æ”¹æ­£æ–‡ä¹‹å‰ï¼Œä¿ç•™ä¸€ä»½åŸå§‹ HTML ä¾›æ®µæ ‡é¢˜æå–é¦–å¥
                            _orig_html_for_snippet = content if isinstance(content, str) else ""
                            comments_content = self._render_segment_comments_xhtml(
                                title,
                                chapter_id,
                                seg_data,
                                back_to_chapter=chapter_file,
                                chapter_html=_orig_html_for_snippet,
                            )
                            try:
                                # ç”Ÿæˆè¾…åŠ©é¡µé¢ï¼ˆä¸è¿› spineï¼‰
                                epub.add_aux_page(comments_title, comments_content, comments_file)
                                # ç»Ÿè®¡æœ‰è¯„è®ºçš„æ®µæ•°é‡ï¼Œç”¨äºé“¾æ¥æç¤º
                                paras = seg_data.get("paras") if isinstance(seg_data, dict) else None
                                seg_para_count = 0
                                seg_counts = {}
                                if isinstance(paras, dict):
                                    for _k, _v in paras.items():
                                        try:
                                            c = int((_v or {}).get("count", 0))
                                        except Exception:
                                            c = 0
                                        if c > 0:
                                            seg_counts[str(_k)] = c
                                            seg_para_count += 1
                                hint = f"ï¼ˆ{seg_para_count}æ®µæœ‰è¯„è®ºï¼‰" if seg_para_count > 0 else ""
                                seg_link = f"\n<p class=\"segment-comments-link\"><a href=\"{comments_file}\">æŸ¥çœ‹æœ¬ç« æ®µè¯„{hint}</a></p>"
                                # å°†æ­£æ–‡ä¸­â€œæœ‰è¯„è®ºçš„æ®µè½â€è½¬æ¢ä¸ºå¯ç‚¹å‡»åŒºåŸŸï¼Œç‚¹å‡»è·³è½¬åˆ°å¯¹åº”æ®µè¯„
                                if isinstance(content, str) and isinstance(paras, dict) and seg_para_count > 0:
                                    try:
                                        # å°†è®¡æ•°å­—å…¸ä¼ å…¥ï¼Œä¾¿äºåœ¨æ®µå°¾è¿½åŠ ç°è‰²å°æ•°å­—
                                        content = self._inject_segment_links(content, comments_file, seg_counts)
                                    except Exception:
                                        pass
                            except Exception as e:
                                # æ®µè¯„å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                                self.logger.debug(f"æ®µè¯„é¡µé¢ç”Ÿæˆå¤±è´¥: {e}")

                    # ç« èŠ‚åŠ å…¥å¯ç‚¹å‡»çš„æ®µè¯„å…¥å£
                    content_with_link = content + seg_link if isinstance(content, str) else content

                    epub.add_chapter(
                        title,
                        content_with_link,
                        file_name=chapter_file,
                    )
                epub.generate(output_file)
                self.logger.info(
                    f"EPUBç”Ÿæˆå®Œæˆ: {self.save_dir / f'{self.book_name}.epub'}"
                )
            else:
                with output_file.open("w", encoding="utf-8") as f:
                    f.write(
                        f"ä¹¦å: {self.book_name}\nä½œè€…: {self.author}\næ ‡ç­¾: {self.tags}\nç®€ä»‹: {self.description}\n\n"
                    )
                    for chapter in chapters:
                        chapter_id = chapter["id"]
                        title = self.downloaded.get(chapter_id, [chapter["title"], None])[0]
                        content = self.downloaded.get(
                            chapter_id,
                            [None, "Download Faild or Didn't Download Finish!"],
                        )[1]
                        f.write(f"\n\n{title}\n{content}")
                self.logger.info(f"TXTç”Ÿæˆå®Œæˆ: {output_file}")
        if result == 0 and self.config.auto_clear_dump and self.end:
            cover_path = self.status_folder / f"{self.book_name}.jpg"
            if self.status_file.exists():
                os.remove(self.status_file)
                self.logger.debug(f"æ–­ç‚¹ç¼“å­˜æ–‡ä»¶å·²æ¸…ç†ï¼{self.status_file}")
            if cover_path.exists():
                os.remove(cover_path)
                self.logger.debug(f"å°é¢æ–‡ä»¶å·²æ¸…ç†ï¼{cover_path}")
            FileCleaner.clean_dump_folder(self.config.get_status_folder_path)

    def save_download_status(self):
        """ä¿å­˜å®Œæ•´ä¸‹è½½çŠ¶æ€"""
        if self.downloaded:
            data = {
                "book_name": self.book_name,
                "author": self.author,
                "tags": self.tags,
                "description": self.description,
                "downloaded": self.downloaded,
            }
            try:
                with self.status_file.open("w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                self.logger.warning(f"çŠ¶æ€æ–‡ä»¶ä¿å­˜å¤±è´¥æˆ–æ— éœ€ä¿å­˜: {e}")

    # ================= æ®µè¯„ â†’ XHTML æ¸²æŸ“ =================
    def _load_segment_comments_json(self, chapter_id: str):
        """è¯»å–æŸç« æ®µè¯„ JSONï¼Œå­˜åœ¨åˆ™è¿”å›å­—å…¸ï¼Œä¸å­˜åœ¨æˆ–å¼‚å¸¸è¿”å› Noneã€‚"""
        try:
            seg_path = self.status_folder / "segment_comments" / f"{chapter_id}.json"
            if not seg_path.exists():
                return None
            with seg_path.open("r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            self.logger.debug(f"æ®µè¯„JSONè¯»å–å¤±è´¥: {e}")
            return None

    def _safe_get(self, obj, keys, default=""):
        """ä» obj ä¸­æŒ‰ keys é¡ºåºå–ç¬¬ä¸€ä¸ªéç©ºå­—æ®µï¼Œkeys å¯ä¸º ['a','b','c'] æˆ–åµŒå¥— 'user.nick'ã€‚"""
        for k in keys:
            try:
                cur = obj
                for part in k.split('.'):
                    if isinstance(cur, dict):
                        cur = cur.get(part)
                    else:
                        cur = None
                        break
                if cur not in (None, ""):
                    return cur
            except Exception:
                continue
        return default

    def _deep_find_str(self, obj, candidate_keys=("text", "message", "content", "title")):
        """åœ¨åµŒå¥— dict/list ä¸­å¯»æ‰¾ç¬¬ä¸€ä¸ªéç©ºå­—ç¬¦ä¸²ï¼Œä¼˜å…ˆåŒ¹é…æŒ‡å®š key åã€‚"""
        try:
            # å‘½ä¸­ä¼˜å…ˆ key
            if isinstance(obj, dict):
                for k in candidate_keys:
                    v = obj.get(k)
                    if isinstance(v, str) and v.strip():
                        return v
                # æ·±æœ
                for v in obj.values():
                    r = self._deep_find_str(v, candidate_keys)
                    if isinstance(r, str) and r.strip():
                        return r
            elif isinstance(obj, list):
                for v in obj:
                    r = self._deep_find_str(v, candidate_keys)
                    if isinstance(r, str) and r.strip():
                        return r
        except Exception:
            pass
        return ""

    def _deep_find_int(self, obj, candidate_keys=("digg_count", "like_count", "praise_count", "likes")):
        """åœ¨åµŒå¥—ç»“æ„ä¸­å¯»æ‰¾ç¬¬ä¸€ä¸ªå¯è½¬ä¸º int çš„æ•°å€¼ï¼Œä¼˜å…ˆåŒ¹é…æŒ‡å®š key åã€‚"""
        try:
            if isinstance(obj, dict):
                for k in candidate_keys:
                    if k in obj:
                        try:
                            return int(obj[k])
                        except Exception:
                            pass
                for v in obj.values():
                    r = self._deep_find_int(v, candidate_keys)
                    if isinstance(r, int) and r >= 0:
                        return r
            elif isinstance(obj, list):
                for v in obj:
                    r = self._deep_find_int(v, candidate_keys)
                    if isinstance(r, int) and r >= 0:
                        return r
        except Exception:
            pass
        return 0

    # ===== è¡¨æƒ…ä¸å›¾ç‰‡å¤„ç† =====
    _EMOJI_MAP = {
        "å¥¸ç¬‘": "ğŸ¤ª",
        "ä½ ç»†å“": "ğŸµ",
        "å¾®ç¬‘": "ğŸ™‚",
        "ç¬‘å“­": "ğŸ˜‚",
        "å¤§ç¬‘": "ğŸ˜„",
        "å·ç¬‘": "ğŸ¤­",
        "è‹¦ç¬‘": "ğŸ˜…",
        "å¤§å“­": "ğŸ˜­",
        "å“­": "ğŸ˜¢",
        "å†è§": "ğŸ‘‹",
        "å®³ç¾": "ğŸ˜Š",
        "OK": "ğŸ‘Œ",
        "OKæ‰‹åŠ¿": "ğŸ‘Œ",
        "OKå•¦": "ğŸ‘Œ",
        "èµ": "ğŸ‘",
        "é¼“æŒ": "ğŸ‘",
        "æ¡æ‰‹": "ğŸ¤",
        "å¼º": "ğŸ’ª",
        "é…·": "ğŸ˜",
        "è‰²": "ğŸ˜˜",
        "äº²äº²": "ğŸ˜˜",
        "ç”Ÿæ°”": "ğŸ˜ ",
        "å‘æ€’": "ğŸ˜¡",
        "æƒŠè®¶": "ğŸ˜®",
        "åèˆŒ": "ğŸ˜›",
        "æ‚è„¸": "ğŸ¤¦",
        "æ€è€ƒ": "ğŸ¤”",
        "ç¡": "ğŸ˜´",
        "ç–‘é—®": "â“",
        "å¿ƒ": "â¤ï¸",
        "å¿ƒç¢": "ğŸ’”",
    }

    def _convert_bracket_emojis(self, text: str) -> str:
        """å°†å½¢å¦‚ [å·ç¬‘] çš„è¡¨æƒ…ä»£ç æ›¿æ¢ä¸º emojiã€‚"""
        if not isinstance(text, str) or "[" not in text:
            return text
        def _repl(m):
            key = m.group(1).strip()
            return self._EMOJI_MAP.get(key, m.group(0))
        try:
            return re.sub(r"\[([^\[\]]+)\]", _repl, text)
        except Exception:
            return text

    def _extract_image_urls(self, obj) -> List[str]:
        """ä»…ä»æ®µè¯„å†…å®¹çš„ content.image_data_list.image_data[*] æå–å›¾ç‰‡ URLï¼Œé¿å…æŠ“å–å¤´åƒ/å°é¢ç­‰æ— å…³é“¾æ¥ã€‚"""
        urls: List[str] = []

        def _add_candidate(s: str | None):
            if isinstance(s, str) and s.startswith("http"):
                urls.append(s)

        try:
            if not isinstance(obj, dict):
                return []

            # ä¼˜å…ˆä»æ ‡å‡†è·¯å¾„æå–ï¼šcomment.common.content.image_data_list
            content = (
                ((obj.get("comment") or {}).get("common") or {}).get("content")
                if isinstance(obj.get("comment"), dict)
                else None
            )
            if not isinstance(content, dict):
                # å…¼å®¹ä½ç½®ï¼šcommon.content / content
                content = ((obj.get("common") or {}).get("content")) if isinstance(obj.get("common"), dict) else obj.get("content")

            if isinstance(content, dict):
                idl = content.get("image_data_list")
                if isinstance(idl, dict):
                    items = idl.get("image_data")
                    if isinstance(items, list):
                        for it in items:
                            if isinstance(it, dict):
                                _add_candidate(
                                    it.get("expand_web_url")
                                    or it.get("web_uri")
                                    or it.get("url")
                                    or it.get("src")
                                )

            # å»é‡
            seen = set()
            dedup = []
            for u in urls:
                if u not in seen:
                    seen.add(u)
                    dedup.append(u)
            return dedup
        except Exception:
            return []

    def _extract_avatar_url(self, item) -> str | None:
        """ä»è¯„è®ºå¯¹è±¡ä¸­æå–ç”¨æˆ·å¤´åƒ URLï¼ˆè‹¥å­˜åœ¨ï¼‰ã€‚"""
        try:
            url = self._safe_get(
                item,
                [
                    "comment.common.user_info.base_info.user_avatar",
                    "common.user_info.base_info.user_avatar",
                    "user_info.base_info.user_avatar",
                    "comment.user_info.base_info.user_avatar",
                    "user.avatar",
                    "avatar_url",
                    "avatar",
                ],
                "",
            )
            if isinstance(url, str) and url.startswith("http"):
                return url
        except Exception:
            pass
        return None

    def _prefetch_media(self, seg_data: dict, top_n: int = 10) -> None:
        """å¹¶å‘é¢„å–æ®µè¯„ä¸­çš„å›¾ç‰‡ä¸å¤´åƒï¼Œä»…å¤„ç†æ¯æ®µå‰ top_n æ¡è¯„è®ºã€‚"""
        try:
            # è‹¥é…ç½®ä¸å…è®¸ä¸‹è½½è¯„è®ºå›¾ç‰‡ï¼Œä»…é¢„å–å¤´åƒ
            allow_images = bool(getattr(self.config, "download_comment_images", True))
            paras = seg_data.get("paras") if isinstance(seg_data, dict) else None
            if not isinstance(paras, dict):
                return
            urls = []
            img_cnt = 0
            avatar_cnt = 0
            for _k, _meta in paras.items():
                detail = (_meta or {}).get("detail") or {}
                lst = detail.get("data_list") if isinstance(detail, dict) else None
                if not isinstance(lst, list) or not lst:
                    continue
                for item in lst[: max(0, int(top_n))]:
                    # è¯„è®ºå›¾ç‰‡ï¼ˆå—å¼€å…³æ§åˆ¶ï¼‰
                    if allow_images:
                        for u in self._extract_image_urls(item):
                            urls.append(u)
                            img_cnt += 1
                    # å¤´åƒ
                    av = self._extract_avatar_url(item)
                    if av:
                        urls.append(av)
                        avatar_cnt += 1
            # å»é‡
            unique = []
            seen = set()
            for u in urls:
                if u not in seen:
                    seen.add(u)
                    unique.append(u)
            if not unique:
                # æç¤ºæ²¡æœ‰å¯ä¸‹è½½åª’ä½“ï¼Œä¾¿äºç”¨æˆ·åˆ¤æ–­ä¸ºä½•è¿›åº¦æ¡ä¸åŠ¨
                try:
                    self.logger.debug(
                        f"[åª’ä½“] ç« èŠ‚ {seg_data.get('chapter_id')} æ— å¯ä¸‹è½½èµ„æº (å›¾ç‰‡={img_cnt}, å¤´åƒ={avatar_cnt}, allow_images={allow_images})"
                    )
                except Exception:
                    pass
                return
            # å¹¶å‘ä¸‹è½½
            try:
                workers = int(getattr(self.config, "media_download_workers", 8))
            except Exception:
                workers = 4
            # åˆå§‹åŒ– / å¢é‡æ›´æ–° åª’ä½“è¿›åº¦æ¡ totalï¼ˆè‹¥æ³¨å…¥ï¼‰
            # å·²ç§»é™¤ UI è¿›åº¦æ¡ï¼Œæ— éœ€ total æ›´æ–°
            self._media_prefetched = True
            try:
                self.logger.debug(
                    f"[åª’ä½“] ç« èŠ‚ {seg_data.get('chapter_id')} æ”¶é›†å›¾ç‰‡={img_cnt} å¤´åƒ={avatar_cnt} å»é‡å={len(unique)}"
                )
            except Exception:
                pass
            with ThreadPoolExecutor(max_workers=max(1, workers)) as ex:
                futures = [ex.submit(self._download_comment_image, u) for u in unique]
                for f in as_completed(futures):
                    try:
                        _ = f.result()
                    except Exception:
                        pass
                    # é™é»˜ï¼Œä¸å†æ›´æ–° UI
        except Exception:
            pass

    def _download_comment_image(self, url: str) -> str | None:
        """ä¸‹è½½å›¾ç‰‡åˆ°çŠ¶æ€ç›®å½• images ä¸‹ï¼Œè¿”å›æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰ï¼Œå¤±è´¥è¿”å› Noneã€‚åŒ…å«è¶…æ—¶å’Œé‡è¯•ã€‚"""
        try:
            # å±è”½åŸŸå
            try:
                blocked = list(getattr(self.config, "blocked_media_domains", []))
            except Exception:
                blocked = []
            if any(b and (b in url) for b in blocked):
                self.logger.debug(f"è·³è¿‡è¢«å±è”½åŸŸåçš„å›¾ç‰‡: {url}")
                return None
            img_dir: Path = self.status_folder / "images"
            img_dir.mkdir(parents=True, exist_ok=True)
            parsed = urlparse(url)
            path = parsed.path or ""
            ext = os.path.splitext(path)[1].lower()
            if ext not in [".jpg", ".jpeg", ".png", ".gif", ".webp"]:
                ext = ""
            name = hashlib.sha1(url.encode("utf-8")).hexdigest()
            if not ext:
                ext = ".jpg"
            file_name = f"{name}{ext}"
            out_path = img_dir / file_name
            if out_path.exists():
                return file_name

            accept_hdr = "image/jpeg,image/jpg,image/png,image/gif,*/*;q=0.8"
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36",
                "Accept": accept_hdr,
                "Referer": f"{parsed.scheme}://{parsed.netloc}/",
            }

            # é…ç½®åŒ–è¶…æ—¶ä¸é‡è¯•
            try:
                timeout = float(getattr(self.config, "media_download_timeout", 5.0))
            except Exception:
                timeout = 5.0
            try:
                max_retries = int(getattr(self.config, "media_download_retries", 4))
            except Exception:
                max_retries = 4
            try:
                backoff = float(getattr(self.config, "media_retry_backoff", 0.8))
            except Exception:
                backoff = 0.8

            import time as _t
            attempt = 0
            last_err = None
            while attempt < max_retries:
                try:
                    self.logger.debug(f"ä¸‹è½½è¯„è®ºå›¾ç‰‡: {url} (å°è¯•{attempt+1}/{max_retries})")
                    resp = requests.get(url, headers=headers, timeout=timeout)
                    sc = resp.status_code
                    if sc == 200 and resp.content:
                        # ---- å†…å®¹ç±»å‹ä¸æ‰©å±•å¤„ç† ----
                        ctype = resp.headers.get("Content-Type", "").lower()
                        url_lower = url.lower()
                        # URL è¿¹è±¡ï¼ˆæ›´å®½æ¾ï¼‰
                        heic_url_markers = [".heic", "/heic", "format=heic", "heic=1", "image/heic", "x-oss-process=image/format,heic"]
                        is_heic_hint = any(m in url_lower for m in heic_url_markers) or ("heic" in ctype or "heif" in ctype)
                        # Magic æ£€æµ‹ï¼šåœ¨å‰ 512 å­—èŠ‚ æœç´¢ ftyp + å“ç‰Œ
                        if not is_heic_hint:
                            try:
                                head_bytes = resp.content[:512]
                                pos = head_bytes.find(b"ftyp")
                                if pos != -1:
                                    brand_window = head_bytes[pos+4:pos+16]
                                    if any(b in brand_window for b in [b"heic", b"heif", b"mif1", b"msf1"]):
                                        is_heic_hint = True
                            except Exception:
                                pass
                        debug_formats = getattr(self.config, "log_image_format_debug", False)
                        if is_heic_hint and debug_formats:
                            self.logger.debug(f"æ£€æµ‹åˆ° HEIC æ ¼å¼: url={url} ctype={ctype}")
                        if ext == ".jpg" and "png" in ctype:
                            file_name2 = f"{name}.png"; out_path2 = img_dir / file_name2
                        elif ext == ".jpg" and "gif" in ctype:
                            file_name2 = f"{name}.gif"; out_path2 = img_dir / file_name2
                        elif ext == ".jpg" and "webp" in ctype:
                            file_name2 = f"{name}.webp"; out_path2 = img_dir / file_name2
                        elif ext == ".jpg" and "avif" in ctype:
                            file_name2 = f"{name}.avif"; out_path2 = img_dir / file_name2
                        elif is_heic_hint:
                            file_name2 = f"{name}.heic"; out_path2 = img_dir / file_name2
                        else:
                            file_name2 = file_name; out_path2 = out_path
                        data_bytes = resp.content
                        # å¼ºåˆ¶ç»Ÿä¸€è½¬æˆ JPEGï¼ˆæ–°é…ç½®ï¼‰æˆ–æ—§ webp é…ç½®å…¼å®¹æ˜ å°„
                        try:
                            force_jpeg = bool(getattr(self.config, "force_convert_images_to_jpeg", False)) or bool(getattr(self.config, "force_convert_images_to_webp", False))
                            need_heic_convert = is_heic_hint and getattr(self.config, "convert_heic_to_jpeg", True)
                            if force_jpeg or need_heic_convert:
                                from io import BytesIO
                                buf_in = BytesIO(data_bytes)
                                converted = False
                                # æ³¨å†Œ heic è§£ç 
                                try:
                                    import pillow_heif  # type: ignore
                                    pillow_heif.register_heif_opener()
                                except Exception:
                                    pass
                                try:
                                    from PIL import Image
                                    with Image.open(buf_in) as im:
                                        im = im.convert("RGB")
                                        qj = int(getattr(self.config, "jpeg_quality", 90))
                                        buf_out = BytesIO()
                                        im.save(buf_out, format="JPEG", quality=max(1, min(100, qj)))
                                        data_bytes = buf_out.getvalue()
                                        file_name2 = f"{name}.jpg"; out_path2 = img_dir / file_name2
                                        converted = True
                                except Exception:
                                    converted = False
                                if is_heic_hint and not converted:
                                    if not getattr(self.config, "keep_heic_original", False):
                                        if debug_formats:
                                            self.logger.debug(f"HEIC è½¬ç å¤±è´¥å·²ä¸¢å¼ƒ: url={url}")
                                        return None
                                    else:
                                        if not file_name2.endswith(".heic"):
                                            file_name2 = f"{name}.heic"; out_path2 = img_dir / file_name2
                            elif getattr(self.config, "jpeg_retry_convert", True) and not ("jpeg" in ctype or file_name2.endswith('.jpg') or file_name2.endswith('.jpeg')):
                                from io import BytesIO
                                from PIL import Image
                                buf_in = BytesIO(data_bytes)
                                try:
                                    with Image.open(buf_in) as im:
                                        im = im.convert("RGB")
                                        qj = int(getattr(self.config, "jpeg_quality", 90))
                                        buf_out = BytesIO()
                                        im.save(buf_out, format="JPEG", quality=max(1, min(100, qj)))
                                        data_bytes = buf_out.getvalue()
                                        file_name2 = f"{name}.jpg"; out_path2 = img_dir / file_name2
                                except Exception:
                                    pass
                        except Exception:
                            pass
                        with open(out_path2, "wb") as f:
                            f.write(data_bytes)
                        return file_name2
                    # å¯é‡è¯•çŠ¶æ€ç 
                    if sc in (429, 500, 502, 503, 504):
                        last_err = RuntimeError(f"status={sc}")
                    else:
                        self.logger.debug(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ status={sc} url={url}")
                        return None
                except requests.Timeout as e:
                    last_err = e
                except Exception as e:
                    last_err = e
                attempt += 1
                _t.sleep(backoff * attempt)
            if last_err:
                try:
                    self.logger.debug(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥(é‡è¯•è€—å°½): {last_err}")
                except Exception:
                    pass
            return None
        except Exception as e:
            try:
                self.logger.debug(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")
            except Exception:
                pass
            return None

    def _find_probable_author(self, obj) -> str:
        """å¯å‘å¼åœ¨åµŒå¥—ç»“æ„ä¸­å¯»æ‰¾æœ€å¯èƒ½çš„ç”¨æˆ·å/ä½œè€…åã€‚"""
        try:
            from collections import deque
            q = deque([obj])
            while q:
                x = q.popleft()
                if isinstance(x, dict):
                    for k, v in x.items():
                        if isinstance(v, str) and v.strip():
                            kl = str(k).lower()
                            if (
                                "user" in kl
                                or "author" in kl
                                or "nick" in kl
                                or kl.endswith("name")
                                or kl in {"name", "uname", "screen_name", "nickname", "nick_name", "user_name"}
                            ):
                                s = v.strip()
                                if 1 <= len(s) <= 32:
                                    return s
                        if isinstance(v, (dict, list)):
                            q.append(v)
                elif isinstance(x, list):
                    for v in x:
                        if isinstance(v, (dict, list)):
                            q.append(v)
            return ""
        except Exception:
            return ""

    def _to_cjk_numeral(self, n: int) -> str:
        """å°† 1..99 è½¬æ¢ä¸ºä¸­æ–‡æ•°å­—ï¼ˆç®€æ˜“ï¼Œæ»¡è¶³æ®µåºå·åœºæ™¯ï¼‰ã€‚"""
        digits = "é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹"
        if n <= 0:
            return str(n)
        if n < 10:
            return digits[n]
        if n == 10:
            return "å"
        if n < 20:
            return "å" + digits[n - 10]
        if n < 100:
            shi = n // 10
            ge = n % 10
            return digits[shi] + "å" + (digits[ge] if ge else "")
        return str(n)

    def _extract_para_snippet(self, chapter_html: str, target_idx: int) -> str:
        """ä»ç« èŠ‚ HTML æŒ‰ <p> é¡ºåºæå–ç¬¬ target_idx æ®µçš„é¦–å¥ï¼›å¤±è´¥è¿”å›ç©ºä¸²ã€‚"""
        if not isinstance(chapter_html, str) or target_idx < 0:
            return ""
        try:
            pattern = re.compile(r"(<p\b[^>]*>)(.*?)(</p>)", re.I | re.S)
            idx = 0
            for m in pattern.finditer(chapter_html):
                if idx == target_idx:
                    inner = m.group(2)
                    inner_text = re.sub(r"<[^>]+>", "", inner)
                    inner_text = html.unescape(inner_text).strip()
                    if not inner_text:
                        return ""
                    cut_points = []
                    for sep in ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", "ï¼›", "â€¦"]:
                        p = inner_text.find(sep)
                        if p != -1:
                            cut_points.append(p + 1)
                    end = min(cut_points) if cut_points else min(len(inner_text), 20)
                    return inner_text[:end].strip()
                idx += 1
        except Exception:
            return ""
        return ""

    def _render_segment_comments_xhtml(self, chapter_title: str, chapter_id: str, data: dict, back_to_chapter: str | None = None, chapter_html: str | None = None) -> str:
        """å°†æ®µè¯„ JSON æ¸²æŸ“ä¸ºä¸€ä¸ªç®€å•å¯è¯»ã€ç¬¦åˆ EPUB çš„ HTML ç‰‡æ®µã€‚"""
        # å¤´éƒ¨
        parts: List[str] = []
        parts.append(f"<h2>{html.escape(chapter_title)} - æ®µè¯„</h2>")
        paras = data.get("paras") if isinstance(data, dict) else None
        if not isinstance(paras, dict) or not paras:
            parts.append("<p>æš‚æ— æ®µè¯„æ•°æ®ã€‚</p>")
            return "\n".join(parts)

    # å‡†å¤‡æå–æ®µè½é¦–å¥çš„å·¥å…·

        # æŒ‰æ®µç´¢å¼•æ’åºè¾“å‡º
        for key in sorted(paras.keys(), key=lambda x: int(x) if str(x).isdigit() else 0):
            meta = paras.get(key) or {}
            try:
                cnt = int(meta.get("count", 0))
            except Exception:
                cnt = 0
            if cnt <= 0:
                # è¯¥æ®µæ— è¯„è®º
                continue
            # å±•ç¤ºå±‚å°† 0 åŸºç´¢å¼•æ”¹ä¸º 1 åŸºäººç±»å¯è¯»
            try:
                disp_idx = int(key) + 1
            except Exception:
                disp_idx = key
            # æ„é€ æ ‡é¢˜ï¼šä¸€ã€"æ®µè½é¦–å¥â€¦" (cnt)
            try:
                idx_int = int(key)
            except Exception:
                idx_int = -1
            snippet = self._extract_para_snippet(chapter_html or "", idx_int) if chapter_html else ""
            cjk_idx = self._to_cjk_numeral(int(disp_idx) if str(disp_idx).isdigit() else 0)
            if snippet:
                title_html = (
                    f"<span class=\"para-title\"><span class=\"para-index\">{html.escape(cjk_idx)}ã€</span> "
                    f"<span class=\"para-src\">&quot;{html.escape(snippet)}&quot;</span> <small>({cnt})</small></span>"
                )
            else:
                # å›é€€ï¼šä¿ç•™åŸæ¥çš„â€œç¬¬ N æ®µ (cnt)â€
                title_html = f"<span class=\"para-title\">ç¬¬ {html.escape(str(disp_idx))} æ®µ <small>({cnt})</small></span>"
            parts.append(f"<h3 id=\"para-{html.escape(str(key))}\">{title_html}</h3>")
            if back_to_chapter:
                parts.append(f"<p class=\"back-to-chapter\"><a href=\"{html.escape(back_to_chapter)}#p-{html.escape(str(key))}\">è¿”å›æœ¬ç« ç¬¬ {html.escape(str(disp_idx))} æ®µ</a></p>")
            detail = meta.get("detail") or {}
            lst = detail.get("data_list") if isinstance(detail, dict) else None
            if not isinstance(lst, list) or not lst:
                parts.append("<p>è¯¥æ®µæš‚æ— å¯å±•ç¤ºçš„è¯„è®ºã€‚</p>")
                continue
            # é™åˆ¶ä»…å±•ç¤ºæ¯æ®µå‰ N æ¡
            try:
                top_n = int(getattr(self.config, "segment_comments_top_n", 10))
            except Exception:
                top_n = 10
            show_list = lst[: max(0, int(top_n))]
            parts.append("<ol>")
            for item in show_list:
                # å–è¯„è®ºæ–‡æœ¬ï¼ˆè¦†ç›–å¸¸è§åµŒå¥—è·¯å¾„ï¼‰
                text = self._safe_get(
                    item,
                    [
                        "common.content.text",
                        "content.text",
                        "common.comment.content.text",
                        "comment.content.text",
                        # æ¬¡çº§ï¼šå¯èƒ½æ‹¿åˆ°ä¸€ä¸ª content dictï¼Œç»§ç»­å–å…¶ä¸­çš„ text
                        "common.content",
                        "comment.content",
                        "text",
                        "msg",
                        "message",
                    ],
                    "",
                )
                # å¦‚æœæ‹¿åˆ°çš„æ˜¯ dictï¼Œå°½é‡å‘å†…å– textï¼›ä»éå­—ç¬¦ä¸²å†åºåˆ—åŒ–å…œåº•
                if isinstance(text, dict):
                    inner_text = self._safe_get(text, ["text", "message"], "")
                    text = inner_text if isinstance(inner_text, str) and inner_text else text
                # ç»“æ„ä»æœªå–åˆ°æœ‰æ•ˆæ–‡æœ¬æ—¶ï¼Œåšä¸€æ¬¡æ·±åº¦å›é€€
                if not isinstance(text, str) or not text.strip():
                    text = self._deep_find_str(item)
                if isinstance(text, (dict, list)):
                    text = json.dumps(text, ensure_ascii=False)
                # è¡¨æƒ…æ›¿æ¢ï¼ˆå…ˆæ›¿æ¢å†è½¬ä¹‰ï¼Œä¿ç•™ emojiï¼‰
                text = self._convert_bracket_emojis(str(text))
                text = html.escape(text)
                # æå–å¹¶ä¸‹è½½å›¾ç‰‡
                img_urls = self._extract_image_urls(item)
                img_tags = []
                for u in img_urls[:6]:  # æ¯æ¡è¯„è®ºæœ€å¤šæ’å…¥ 6 å¼ ä»¥é˜²è¿‡å¤š
                    fn = self._download_comment_image(u)
                    if fn:
                        img_tags.append(f'<img src="images/{html.escape(fn)}" alt="img" />')
                # å–ä½œè€…ï¼šè¦†ç›–å¸¸è§è·¯å¾„ + æ›´ç¨³å¥å›é€€
                author = self._safe_get(
                    item,
                    [
                        # å¸¸è§
                        "common.user_info.base_info.user_name",
                        "user_info.base_info.user_name",
                        "common.user_info.base_info.nickname",
                        "user_info.base_info.nickname",
                        "common.user.nick_name",
                        "common.user.nickname",
                        "user.nick_name",
                        "user.nickname",
                        "user.name",
                        # å˜ä½“
                        "user_info.user_name",
                        "user_info.nickname",
                        "common.user_info.user_name",
                        "common.user_info.nickname",
                        "common.user_name",
                        "screen_name",
                        "uname",
                        "nick",
                        # é€šç”¨
                        "author",
                        "nickname",
                        "user_name",
                        "name",
                    ],
                    "",
                )
                if not isinstance(author, str) or not author.strip():
                    author = self._deep_find_str(item, ("user_name", "nickname", "nick_name", "name", "screen_name", "uname", "nick"))
                if not isinstance(author, str) or not author.strip():
                    author = self._find_probable_author(item)
                if not isinstance(author, str) or not author.strip():
                    author = "åŒ¿å"
                author = html.escape(str(author))
                # ç‚¹èµ/çƒ­åº¦ï¼ˆè¦†ç›–å¸¸è§åµŒå¥—è·¯å¾„ï¼Œä¼˜å…ˆ comment.stat.digg_countï¼‰
                like = self._safe_get(
                    item,
                    [
                        # æ­£ç¡®æ‰€åœ¨ä½ç½®
                        "comment.stat.digg_count",
                        "comment.stat.like_count",
                        "comment.stat.praise_count",
                        # å…¶å®ƒå¯èƒ½ä½ç½®ï¼ˆå…¼å®¹å†å²/å˜ä½“ï¼‰
                        "stat.digg_count",
                        "common.digg_count",
                        "digg_count",
                        "like_count",
                        "praise_count",
                        "likes",
                    ],
                    0,
                )
                try:
                    like = int(like)
                except Exception:
                    like = 0
                if like == 0:
                    # ä»…åœ¨ comment å­å¯¹è±¡å†…åšå›é€€æœç´¢ï¼Œé¿å…æ‹¿åˆ°æ— å…³çš„ 0 å€¼
                    sub = item.get("comment") if isinstance(item, dict) else None
                    like = self._deep_find_int(sub if isinstance(sub, (dict, list)) else item)
                # æ—¶é—´ï¼ˆè‹¥æœ‰ï¼‰
                ts = self._safe_get(
                    item,
                    [
                        "common.create_timestamp",
                        "create_timestamp",
                        "create_time",
                        "ctime",
                        "time",
                    ],
                    "",
                )
                # å°è¯•å°†æ—¶é—´æˆ³æ ¼å¼åŒ–æˆäººç±»å¯è¯»
                try:
                    import time as _t
                    if isinstance(ts, (int, float)):
                        # ç»å¤§å¤šæ•°ä¸ºç§’çº§æ—¶é—´æˆ³
                        if ts > 1e12:
                            # æ¯«ç§’
                            ts = int(ts / 1000)
                        else:
                            ts = int(ts)
                        ts = _t.strftime("%Y-%m-%d %H:%M", _t.localtime(ts))
                except Exception:
                    pass
                ts = html.escape(str(ts)) if ts else ""
                # å¤´åƒ
                avatar_url = self._extract_avatar_url(item)
                avatar_img = ""
                if avatar_url:
                    fn_av = self._download_comment_image(avatar_url)
                    if fn_av:
                        avatar_img = f'<img class="avatar" src="images/{html.escape(fn_av)}" alt="avatar" /> '

                meta_line = f"<small class=\"seg-meta\">{avatar_img}ä½œè€…ï¼š{author}"
                if ts:
                    meta_line += f" | æ—¶é—´ï¼š{ts}"
                meta_line += f" | èµï¼š{like}</small>"
                if img_tags:
                    parts.append(f"<li class=\"seg-item\"><p>{text}</p><div class=\"seg-images\">{''.join(img_tags)}</div><p>{meta_line}</p></li>")
                else:
                    parts.append(f"<li class=\"seg-item\"><p>{text}</p><p>{meta_line}</p></li>")
            parts.append("</ol>")

        # ç®€å•ç»“å°¾
        try:
            n = int(getattr(self.config, "segment_comments_top_n", 10))
        except Exception:
            n = 10
        parts.append(f"<p><small>ä»…å±•ç¤ºæ¯æ®µå‰ {n} æ¡è¯„è®ºï¼ˆè‹¥æœ‰ï¼‰ï¼Œå®é™…æ€»æ•°ä»¥æ¥å£ä¸ºå‡†ã€‚</small></p>")
        return "\n".join(parts)

    def _inject_segment_links(self, content_html: str, comments_file: str, seg_counts: dict) -> str:
        """
        å°†æ­£æ–‡ä¸­â€œæœ‰è¯„è®ºçš„æ®µè½â€åœ¨æ®µå°¾è¿½åŠ ä¸€ä¸ªç°è‰²å°æ•°å­—ï¼ˆè¯„è®ºæ•°ï¼‰ï¼Œç‚¹å‡»è·³è½¬è‡³å¯¹åº”æ®µè¯„é”šç‚¹ï¼›åŒæ—¶ä¸ºè¿™äº›æ®µè½åŠ ä¸Š id="p-<idx>"
        è¯´æ˜ï¼š
        - é€ä¸ªåŒ¹é… <p>â€¦</p>ï¼ŒæŒ‰å‡ºç°é¡ºåºä½œä¸ºæ®µç´¢å¼• 0,1,2,...
        - è‹¥è¯¥ç´¢å¼•åœ¨ seg_counts å†…ä¸” >0ï¼Œåˆ™åœ¨æ®µå°¾è¿½åŠ  <a class="seg-count">(N)</a>
          å¹¶ä¸º <p> å¢åŠ  id="p-idx"ï¼ˆè‹¥åŸæœ¬æ—  idï¼‰ã€‚
        - ç®€åŒ–å®ç°ï¼Œæœªæ‹†åˆ†ä¸ºå¥çº§é“¾æ¥ï¼›ä¿æŒæ­£æ–‡é¢œè‰²ä¸å˜ã€‚
        """
        try:
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ \b æ˜¯æ­£åˆ™â€œå•è¯è¾¹ç•Œâ€ï¼Œraw-string ä¸‹æ— éœ€å†åŒåæ–œæ 
            pattern = re.compile(r"(<p\b[^>]*>)(.*?)(</p>)", re.I | re.S)
            idx = 0
            out = []
            last = 0
            for m in pattern.finditer(content_html):
                out.append(content_html[last:m.start()])
                open_tag, inner, close_tag = m.group(1), m.group(2), m.group(3)
                # ä»…å¯¹æœ‰è¯„è®ºçš„æ®µè½å¤„ç†
                cnt = 0
                try:
                    cnt = int(seg_counts.get(str(idx), 0))
                except Exception:
                    cnt = 0
                if cnt > 0:
                    # è‹¥æ—  idï¼Œè¿½åŠ  id="p-idx"
                    if not re.search(r"\bid\s*=", open_tag, re.I):
                        open_tag = open_tag[:-1] + f' id="p-{idx}">'
                    # åœ¨æ®µå°¾è¿½åŠ ç°è‰²å¯ç‚¹å‡»æ•°å­—
                    badge = (
                        f' <a class="seg-count" href="{html.escape(comments_file)}#para-{idx}" '
                        f'title="æŸ¥çœ‹æœ¬æ®µè¯„è®º">({cnt})</a>'
                    )
                    inner = inner + badge
                out.append(open_tag + inner + close_tag)
                last = m.end()
                idx += 1
            out.append(content_html[last:])
            return "".join(out)
        except Exception:
            return content_html
