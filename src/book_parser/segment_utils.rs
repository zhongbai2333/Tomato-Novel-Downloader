//! æ®µè¯„/è¯„è®ºç›¸å…³çš„è§£æä¸æ‹¼è£…å·¥å…·ã€‚

use regex::Regex;

/// å°† [ç¬‘] å½¢å¼çš„ç®€å•è¡¨æƒ…æ›¿æ¢ä¸º emojiã€‚
pub fn convert_bracket_emojis(text: &str) -> String {
    if !text.contains('[') {
        return text.to_string();
    }
    let map = emoji_map();
    let re = Regex::new(r"\[([\u4e00-\u9fa5]{1,4})\]").unwrap();
    re.replace_all(text, |caps: &regex::Captures| {
        let key = caps.get(1).map(|m| m.as_str()).unwrap_or("");
        map.get(key).cloned().unwrap_or_else(|| caps[0].to_string())
    })
    .to_string()
}

pub fn to_cjk_numeral(n: i32) -> String {
    let digits = ["é›¶", "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹"];
    if n <= 0 {
        return n.to_string();
    }
    if n < 10 {
        return digits[n as usize].to_string();
    }
    if n == 10 {
        return "å".to_string();
    }
    if n < 20 {
        return format!("å{}", digits[(n - 10) as usize]);
    }
    if n < 100 {
        let shi = n / 10;
        let ge = n % 10;
        if ge == 0 {
            format!("{}å", digits[shi as usize])
        } else {
            format!("{}å{}", digits[shi as usize], digits[ge as usize])
        }
    } else {
        n.to_string()
    }
}

/// æ£€æŸ¥æ®µè½æ˜¯å¦åº”è¯¥åœ¨æ®µè¯„è®¡æ•°æ—¶è·³è¿‡ï¼ˆå¦‚å›¾ç‰‡åŒ…è£…æ®µè½ã€å·æ ‡é¢˜ç­‰ï¼‰ã€‚
fn should_skip_para_for_comments(open_tag: &str) -> bool {
    let lower = open_tag.to_ascii_lowercase();
    // Skip paragraphs that are wrappers for images (not counted as content paragraphs by the API)
    if lower.contains("class=\"picture\"") || lower.contains("class='picture'") {
        return true;
    }
    // Skip paragraphs with volume/section/catalog titles (added by new volume feature)
    if lower.contains("class=\"volumetitle\"") || lower.contains("class='volumetitle'")
        || lower.contains("class=\"sectiontitle\"") || lower.contains("class='sectiontitle'")
        || lower.contains("class=\"catalogtitle\"") || lower.contains("class='catalogtitle'")
        || lower.contains("class=\"volume-title\"") || lower.contains("class='volume-title'")
        || lower.contains("class=\"section-title\"") || lower.contains("class='section-title'")
        || lower.contains("class=\"catalog-title\"") || lower.contains("class='catalog-title'")
    {
        return true;
    }
    false
}

/// æå–æŒ‡å®šæ®µè½çš„çº¯æ–‡æœ¬æ‘˜è¦ï¼ˆç”¨äºæ®µè¯„å›é“¾ï¼‰ã€‚
pub fn extract_para_snippet(chapter_html: &str, target_idx: usize) -> String {
    let re = Regex::new(r"(<p[^>]*>)(.*?)(</p>)").unwrap();
    let mut content_idx = 0;
    for cap in re.captures_iter(chapter_html) {
        let open_tag = cap.get(1).map(|m| m.as_str()).unwrap_or("");
        // Skip non-content paragraphs to match API's paragraph counting
        if should_skip_para_for_comments(open_tag) {
            continue;
        }
        if content_idx == target_idx {
            let inner = cap.get(2).map(|m| m.as_str()).unwrap_or("");
            let inner_text = strip_tags(inner).trim().to_string();
            if inner_text.is_empty() {
                return String::new();
            }
            let cut = ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", "ï¼›", "â€¦"]
                .iter()
                .filter_map(|sep| inner_text.find(sep).map(|p| p + sep.len()))
                .min()
                .unwrap_or_else(|| inner_text.len().min(20));
            return inner_text[..cut].trim().to_string();
        }
        content_idx += 1;
    }
    String::new()
}

pub fn inject_segment_links(
    content_html: &str,
    comments_file: &str,
    seg_counts: &serde_json::Map<String, serde_json::Value>,
) -> String {
    // Mirror Python logic in `segment_utils.py`:
    // - iterate <p> in-order with a monotonically increasing idx
    // - SKIP non-content paragraphs (picture wrappers, volume titles, etc.) to match API counting
    // - if cnt>0 and <p> has no id=, add id="p-{idx}" while preserving other attrs
    // - append a badge link to the segment comment page
    let re = Regex::new(r"(?is)(<p\b[^>]*>)(.*?)(</p>)").unwrap();
    let re_has_id = Regex::new(r"(?is)\bid\s*=").unwrap();

    let mut out = String::new();
    let mut last_end = 0usize;
    let mut content_idx = 0usize; // Index for content paragraphs only

    for m in re.find_iter(content_html) {
        out.push_str(&content_html[last_end..m.start()]);

        let caps = re.captures(m.as_str()).unwrap();
        let mut open_tag = caps.get(1).map(|m| m.as_str()).unwrap_or("").to_string();
        let mut inner = caps.get(2).map(|m| m.as_str()).unwrap_or("").to_string();
        let close_tag = caps.get(3).map(|m| m.as_str()).unwrap_or("");

        // Skip non-content paragraphs to match API's paragraph counting
        if should_skip_para_for_comments(&open_tag) {
            out.push_str(&open_tag);
            out.push_str(&inner);
            out.push_str(close_tag);
            last_end = m.end();
            continue;
        }

        let cnt = seg_counts
            .get(&content_idx.to_string())
            .and_then(|v| v.as_u64())
            .unwrap_or(0);

        if cnt > 0 {
            if !re_has_id.is_match(&open_tag) && open_tag.ends_with('>') {
                open_tag.pop();
                open_tag.push_str(&format!(" id=\"p-{}\">", content_idx));
            }
            inner.push_str(&format!(
                " <a class=\"seg-count\" href=\"{}#para-{}\" title=\"æŸ¥çœ‹æœ¬æ®µè¯„è®º\">({})</a>",
                html_escape_attr(comments_file),
                content_idx,
                cnt
            ));
        }

        out.push_str(&open_tag);
        out.push_str(&inner);
        out.push_str(close_tag);

        last_end = m.end();
        content_idx += 1; // Only increment for content paragraphs
    }

    out.push_str(&content_html[last_end..]);
    out
}

fn html_escape_attr(input: &str) -> String {
    // Sufficient for EPUB internal href attr.
    input
        .replace('&', "&amp;")
        .replace('<', "&lt;")
        .replace('>', "&gt;")
        .replace('"', "&quot;")
        .replace('\'', "&#39;")
}

fn strip_tags(raw: &str) -> String {
    let re = Regex::new(r"<[^>]+>").unwrap();
    re.replace_all(raw, "").to_string()
}

fn emoji_map() -> std::collections::HashMap<&'static str, String> {
    use std::collections::HashMap;
    let mut m = HashMap::new();
    m.insert("ç¬‘", "ğŸ˜„".to_string());
    m.insert("å“­", "ğŸ˜­".to_string());
    m.insert("æ±—", "ğŸ˜…".to_string());
    m.insert("æ€’", "ğŸ˜¡".to_string());
    m.insert("ç—›", "ğŸ˜£".to_string());
    m.insert("èµ", "ğŸ‘".to_string());
    m.insert("è¸©", "ğŸ‘".to_string());
    m.insert("æƒŠ", "ğŸ˜²".to_string());
    m.insert("ç–‘", "ğŸ¤”".to_string());
    m.insert("è‰²", "ğŸ˜".to_string());
    m.insert("å‘†", "ğŸ˜".to_string());
    m.insert("å", "ğŸ˜ˆ".to_string());
    m.insert("å¥¸ç¬‘", "ğŸ˜".to_string());
    m.insert("èˆ”å±", "ğŸ¤¤".to_string());
    m.insert("å§”å±ˆ", "ğŸ¥º".to_string());
    m.insert("é£å»", "ğŸ˜˜".to_string());
    m.insert("é…·", "ğŸ˜".to_string());
    m.insert("é€å¿ƒ", "ğŸ’–".to_string());
    m.insert("æˆ‘ä¹Ÿå¼ºæ¨", "ğŸ’¯".to_string());
    m.insert("æƒŠå‘†", "ğŸ˜²".to_string());
    m.insert("å·ç¬‘", "ğŸ¤­".to_string());
    m.insert("ç¿»ç™½çœ¼", "ğŸ™„".to_string());
    m.insert("çŸ³åŒ–", "ğŸ—¿".to_string());
    m
}
